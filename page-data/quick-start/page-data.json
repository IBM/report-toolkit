{"componentChunkName":"component---src-pages-quick-start-index-mdx","path":"/quick-start/","result":{"pageContext":{"frontmatter":{"title":"report-toolkit Quick Start"},"relativePagePath":"/quick-start/index.mdx","titleType":"append","MdxNode":{"id":"a72e8aaf-8df0-5391-9797-c3b13a3331f9","children":[],"parent":"b4e9308e-f2bd-551e-b38a-a9823c455783","internal":{"content":"---\ntitle: report-toolkit Quick Start\n---\n\nimport {Metadata, EmbedCode} from '../../components';\nimport {reportExample} from './index.module.scss';\n\n<PageDescription>\n\nThis \"quick start\" guide will provide an overview of <Metadata prop=\"packageName\"/>'s capabilities.\n\nUse the links below to jump to a section, or just <a href=\"#install\">install <Metadata prop=\"packageName\"/></a> and get moving!\n\n</PageDescription>\n\n<AnchorLinks>\n  <AnchorLink>Install</AnchorLink>\n  <AnchorLink>Generate a Diagnostic Report</AnchorLink>\n  <AnchorLink>Redact Secrets From a Report</AnchorLink>\n  <AnchorLink>Compare Two Reports</AnchorLink>\n  <AnchorLink>Detect Problems within a Report</AnchorLink>\n  <AnchorLink>Transforming a Report</AnchorLink>\n  <AnchorLink>Further Reading</AnchorLink>\n</AnchorLinks>\n\n## Install\n\nUnsurprisingly, to use <Metadata prop=\"packageName\"/>, you must install it.\n\n### Prerequisite: Node.js v11.8.0 or newer\n\nFor the purposes of this guide, _you must be running Node.js version v11.8.0 or newer_; the [Diagnostic Reports](https://nodejs.org/api/report.html) API referenced in this guide will reflect its state at version v11.8.0.\n\nHere are some options for installation:\n\n- **Recommended:** An official package from [nodejs.org](https://nodejs.org)\n- **macOS**: [Homebrew](https://brew.sh) (`brew install node`)\n- **Linux**: [NodeSource Binary Distributions](https://github.com/nodesource/distributions)\n- **Windows**: [Chocolatey](https://chocolatey.org/)\n- **Linux/macOS**: A version manager like [nvm](https://github.com/nvm-sh/nvm)\n\n### Package Installation\n\n<Row>\n<Column colMd={5} colLg={8}>\n\nUse your favorite Node.js package manager to install; [`npm`](https://docs.npmjs.com/cli-documentation/) comes packaged with most Node.js distributions.\n\nFor this guide, it's recommended to install <Metadata prop=\"packageName\"/> _globally_:\n\n```bash\n$ npm install report-toolkit --global\n```\n\n</Column>\n<Column colMd={2} colLg={3} offsetMd={1} offsetLg={1}>\n  <Aside>\n\nSee npm's guide on [installing packages globally](https://docs.npmjs.com/downloading-and-installing-packages-globally) for other options and troubleshooting.\n\n  </Aside>\n</Column>\n</Row>\n\n## Generate a Diagnostic Report\n\nTo do much of anything with <Metadata prop=\"packageName\"/>, you must generate a diagnostic report.\n\n<InlineNotification kind=\"info\">\n\nIf you already have a diagnostic report file you intend to use, you can skip\nahead to the [next section](#redact-secrets-from-a-report).\n\n</InlineNotification>\n\nAt the time of this writing (2019-09-23), the diagnostic report functionality is \"hidden\" behind a flag to the `node` executable; `--experimental-report`.\n\nThe quickest way to generate a report is to evaluate an inline script, like so:\n\n```bash\nnode --experimental-report --report-filename report.json --eval \"process.report.writeReport()\"\n```\n\nYou'll see this:\n\n```\nWriting Node.js report to file: report.json\nNode.js report completed\n(node:18881) ExperimentalWarning: report is an experimental feature. This feature could change at any time\n```\n\nBreaking down the arguments to `node`, we have:\n\n1. `--experimental-report`; enables diagnostic report functionality\n1. `--report-filename report.json`; whenever a diagnostic report is written to disk, use this filename\n1. `--eval \"process.report.writeReport()\"`; instead of a `.js` file, execute the double-quoted string as a script, then exit. The script calls [process.report.writeReport()](https://nodejs.org/api/process.html#process_process_report_writereport_filename_err), which writes a report file to disk.\n\n<p>\n  Next, you'll see how <Metadata prop=\"packageName\" /> enables safe storage and\n  transmission of report files.\n</p>\n\n## Redact Secrets From a Report\n\nOpen `report.json` in your favorite editor (or use `cat` or `less` or whathaveyou). Scroll down to--or search for--the `environmentVariables` property.\n\n`environmentVariables` is a top-level property of a report file. It contains a complete dump of the environment at the time the report was created. You might notice API keys, cloud provider tokens, credentials, or other session identifiers; in other words, _secrets_.\n\nDepending on your filesystem permissions, `report.json` might even be readable by other users who couldn't otherwise see your environment. This is a potential leak, and we should plug it. <Metadata prop=\"packageName\"/> to the rescue!\n\nThe <Metadata prop=\"packageName\"/> package provides command-line utility, <Metadata prop=\"executable\"/>.\n\nAssuming <Metadata prop=\"packageName\"/> is installed globally, run:\n\n```bash\nrtk --help\n```\n\nYou should see:\n\n<EmbedCode name=\"cli-output\" />\n\nWe see <Metadata prop=\"executable\"/> provides _commands_; the command we want is `redact`.\n\nBy default, the `redact` command will print its output to `STDOUT` (the terminal). Instead, let's use the `--output` option to write to a new file (smarties may also ask their shell to redirect the output to a file):\n\n```bash\nrtk redact --output report-redacted.json report.json\n```\n\n<Row>\n<Column colMd={5} colLg={8}>\n\nNow, open `report-redacted.json` in your editor (or otherwise display it). Search for the `environmentVariables` property. Within this object, you will see `[REDACTED]` wherever <Metadata prop=\"packageName\"/> found a secret.\n\nHere's an example _excerpt_ from `report-redacted.json`:\n\n</Column>\n<Column colMd={2} colLg={3} offsetMd={1} offsetLg={1}>\n  <Aside>\n\nIf <Metadata prop=\"packageName\"/> _didn't_ catch all your secrets, fear not; you can customize its behavior to suit your environment. See the [Configuration Guide](/configuration-guide) for more information.\n\n  </Aside>\n</Column>\n</Row>\n\n```json path=report-redacted.json\n{\n \"environmentVariables\": {\n    \"TERM_SESSION_ID\": \"[REDACTED]\",\n    \"SSH_AUTH_SOCK\": \"[REDACTED]\",\n    \"Apple_PubSub_Socket_Render\": \"[REDACTED]\",\n    \"COLORFGBG\": \"15;0\",\n    \"ITERM_PROFILE\": \"yoyodyne\"\n }\n```\n\nIf you wish, delete your original `report.json`; `report-redacted.json` is now safe to share or send across the wire.\n\nA design goal of <Metadata prop=\"packageName\"/> is _strong security defaults_. It will _always_ automatically redact _all_ reports which it ingests. You can disable this via a flag--see the detailed [CLI Guide](/cli-guide) for more information.\n\nNext, you'll see how <Metadata prop=\"executable\"/> can provide a quick comparison of two reports using its `diff` command.\n\n## Compare Two Reports\n\nIf you're having trouble tracking down the difference between two running `node` processes--say, on two machines that _should_ have identical environments--diagnostic reports and <Metadata prop=\"packageName\"/> can help.\n\nAs you may have deduced, we'll need two (2) reports to proceed.\n\n<InlineNotification>\n\nIf you've completed the [previous section](#redact-secrets-from-a-report), you can re-use `report-redacted.json`; use this filename whenever this section refers to `report-1.json`. Skip ahead to [creating the second report](#create-the-second-report).\n\n</InlineNotification>\n\n### Create the First Report\n\nTo create the first report, named `report-1.json`, execute:\n\n```bash\nnode --experimental-report --report-filename report-1.json \\\n  --eval \"process.report.writeReport()\"\n```\n\nYou'll see:\n\n```plain wrap=true\nWriting Node.js report to file: report-1.json\nNode.js report completed\n(node:18881) ExperimentalWarning: report is an experimental feature. This feature could change at any time\n```\n\n### Create the Second Report\n\nTo create a _second_ report, repeat the command with the filename changed to `report-2.json`:\n\n```bash\nnode --experimental-report --report-filename report-2.json \\\n  --eval \"process.report.writeReport()\"\n```\n\nAnd you will see:\n\n```plain wrap=true\nWriting Node.js report to file: report-2.json\nNode.js report completed\n(node:18881) ExperimentalWarning: report is an experimental feature. This feature could change at any time\n```\n\n<InlineNotification kind=\"warning\">\n  Remember, report files may contain secrets; be deliberate about what you do\n  with these files!\n</InlineNotification>\n\nWith our two reports in-hand, we can use the `diff` command to see what's changed between these two files.\n\n### Running a Diff\n\nA \"diff\" between two reports is _not_ a POSIX diff like you'd see between two versions of the same file. If you want that, you can use the [diff utility](https://en.wikipedia.org/wiki/Diff)!\n\nInstead, <Metadata prop=\"packageName\"/> attempts to disregard typically-irrelevant information, and provide output tailored to the data structure of a report file, which is JSON.\n\nTo display a diff, execute:\n\n```bash\nrtk diff report-1.json report-2.json\n```\n\nYou'll get something like the below (but probably with fancy colors):\n\n<EmbedCode name=\"diff-output\" />\n\nBy default, <Metadata prop=\"executable\"/> will display a diff in a tabular format, intended for human consumption.\n\nIn the table above, we have four (4) columns. Breaking them down:\n\n1. **Op**: This is the _type_ of change. In this case, all changes are _modifications_, denoted by `M`. This means that the field exists in both reports, but the value is different. You may also see `A` for \"added\" (when a field is present in the second report and not the first) and `D` for \"deleted\" (when a field is present in the first but not the second).\n1. **Path**: This is the JSON \"keypath\" of the field. If you were to reference the field like the report is a regular JavaScript object, this is how you would do it. `[]` indicates the presence of an _array_. `header.commandLine[3]`, for example, 4th element of the `commandLine` prop of the root `header` prop.\n1. **report-1.json**: The value at **Path** in `report-1.json` (if present).\n1. **report-2.json**: The corresponding value at **Path** in `report-2.json` (if present).\n\nNote the difference within the `header.commandLine` array. This reflects the different commands we used to generate each report. We could use that information to determine if the same application generated both reports. Likewise, by comparing `header.processId`, we could tell if the same _process_ created both reports.\n\n<Row>\n<Column colMd={5} colLg={8}>\n\nTo squelch noise, by default, the `diff` command shows differences _only_ within these properties:\n\n1. `header`, omitting properties:\n   1. `filename`\n   1. `dumpEventTime`\n   1. `dumpEventTimeStamp`\n   1. `cpus`\n1. `environmentVariables`\n1. `userLimits`\n1. `sharedObjects`\n\n</Column>\n<Column colMd={2} colLg={3} offsetMd={1} offsetLg={1}>\n  <Aside>\n\nYou can control which fields appear in the diff by providing the `--includeProp/-i` and/or `--excludeProp/-x` arguments, or use `--all` to show everything. See the [CLI Guide]() for more in-depth information.\n\n  </Aside>\n</Column>\n</Row>\n\nNext, we'll see how <Metadata prop=\"packageName\"/> can detect problems using its `inspect` command.\n\n## Detect Problems within a Report\n\nA diagnostic report is raw data about a `node` process. If you're familiar with diagnostic reports--or happen to know precisely what you're looking for--you can interpret that data yourself.\n\nBut much like a radiologist reading an X-ray, <Metadata prop=\"packageName\"/> can interpret the raw data in a report and provide akin to a _diagnosis_--or warn about something you may have otherwise overlooked.\n\nGiven a diagnostic report, <Metadata prop=\"packageName\"/> can run a set of _rules_ (heuristics) against it, providing further information if a \"check\" fails. This is similar--and, in fact, patterned on--how [ESLint](http://eslint.org) runs rules against your codebase. Also akin to ESLint, <Metadata prop=\"packageName\"/> ships with a set of built-in rules, which we'll use next.\n\nLet's take one of the reports we've already created (it doesn't matter which). Execute:\n\n```bash\nrtk inspect report-1.json\n```\n\nMost likely, this command will result in _no output_--in other words, success. <Metadata prop=\"executable\"/> didn't find anything worth your attention.\n\nEach _message_ emitted by a rule has an associated _severity_. These severities, from \"most severe\" to \"least severe\", are:\n\n- `error`\n- `warning`\n- `info`\n\nThe default behavior of <Metadata prop=\"executable\"/> is to exclusively show messages with a severity of _error_.\n\nBut you, the user, can control this. Let's change the severity threshold to `info`, and see what happens:\n\n```bash\nrtk inspect report-1.json --severity info\n```\n\nThe output should now look _something_ like this (and in color):\n\n<EmbedCode name=\"inspect-output-1\" />\n\nAbove, we see that two rules (`cpu-usage` and `memory-usage`) each output a message. Reading the message, we see that the allowed CPU usage and memory usage, respectively, are within the default thresholds for each rule.\n\nIf, for example, the CPU usage was greater than 50%, then instead of a message with severity `INFO`, the severity would be displayed as `ERROR`.\n\n<InlineNotification>\n\nWhen a message with severity `ERROR` is encountered during inspection, <Metadata prop=\"executable\"/>'s process with exit with a nonzero code (1).\n\n</InlineNotification>\n\nInstead of printing a fibonacci sequence in another process, we can use an example \"problem\" report file to see what an _actual_ error looks like. <a href=\"/raw/report-high-cpu-usage.example.json\" download>Download <inlineCode>report-high-cpu-usage.example.json</inlineCode></a>; we'll hand this file to `inspect`:\n\n```bash\nrtk inspect report-high-cpu-usage.example.json\n```\n\nNote that the above command _does not_ include `--severity info`. Now, we should see an error:\n\n<EmbedCode name=\"inspect-output-2\" />\n\nIn `report-high-cpu-usage.example.json`, the reported CPU usage (precisely, the _mean_ across all CPUs) is greater than the default threshold of 50%.\n\nYou could use this information to verify that the process isn't taking up too much CPU--or change the range (via a configuration file) to assert the process remains active--or even verify that utilization is high enough to justify paying for the compute!\n\n<InlineNotification>\n\nTo get the most out of the built-in rules--all of which are independently configurable--see the [Configuration Guide](). If you want to make your _own_ custom rules, see the [Plugin Developer's Guide]();\n\n</InlineNotification>\n\nFinally, let's see how <Metadata prop=\"executable\"/>'s `transform` command can help convert a report to a more useful format.\n\n## Transforming a Report\n\nThe `transform` command allows you to apply _one or more_ \"transformers\" to a diagnostic report.\n\nThe list of built-in transformers is as follows:\n\n- `csv`: Converts to CSV format\n- `filter`: Pick or omit certain properties\n- `json`: Converts to JSON format (the default)\n- `newline`: Converts to newline-delimited format, suitable for piping via shell, consumption via Node.js streams, etc.\n- `redact`: Redacts secrets\n- `stack-hash`: Computes a hash of the exception for metrics; helps answer \"have we seen this exception before?\"\n- `table`: The default transform for the `diff` and `inspect` commands, among others\n\nSince this _is_ supposed to be a quick-start guide, we'll pick two of these as examples: [`filter`](#the-filter-transformer) and [`stack-hash`](#the-stack-hash-transformer).\n\n### The `filter` Transformer\n\nThe `filter` transformer allows you to essentially \"whitelist\" or \"blacklist\" some portion of a report (or both at once; the blacklist takes preference).\n\nFor example, if you'd like to retrieve _only_ the version of `node` used to generate the report, you can use:\n\n```bash\nrtk transform -t filter --include header.componentVersions.node \\\n  report-1.json\n```\n\nWhich will result in something like this (depending on the version of `node` you used to generate the report):\n\n<EmbedCode name=\"transform-output-1\" language=\"json\" />\n\nLikewise, the `--exclude` argument would allow you to, say, omit the entirety the `environmentVariables` and `sharedObjects` properties:\n\n```bash\nrtk transform -t filter --exclude environmentVariables --exclude \\\n  sharedObjects report-1.json\n```\n\nAs you can see from the above, `--include` and `--exclude` can be specified multiple times.\n\nFor something more practical, let's try `stack-hash`.\n\n### The `stack-hash` Transformer\n\nThe intent of this transformer is to facilitate the gathering of _metrics_ around exceptions (or more specifically, the stack traces thereof).\n\n`node` can be configured to automatically generate a diagnostic report when it encounters an uncaught exception or a user signal (e.g., `SIGUSR1`). We can then use the `stack-hash` transformer to associate the stack (present in all reports) with a reasonably unique SHA1 hash.\n\nHere's an example of configuring `node` to automatically output a report file upon an uncaught exception (and summarily throwing one via `--eval`):\n\n```bash\nnode --experimental-report --report-filename report-3.json \\\n  --report-uncaught-exception --eval \"throw new Error('oh no')\"\n```\n\nWe can then use the `stack-hash` transformer on `report-3.json`:\n\n```bash\nrtk transform -t stack-hash report-3.json\n```\n\nWhich will result in something akin to:\n\n<EmbedCode name=\"transform-output-2\" language=\"json\" />\n\nIf we repeat the command using a different filename (`report-4.json`):\n\n```bash\nnode --experimental-report --report-filename report-4.json \\\n  --report-uncaught-exception --eval \"throw new Error('oh no')\"\n```\n\nAnd run the transformer:\n\n```bash\nrtk transform -t stack-hash report-4.json\n```\n\nWe'll get the _same_ hash, even though the `dumpEventTime` (when the report file was created) and `filepath` differ:\n\n<EmbedCode name=\"transform-output-3\" language=\"json\" />\n\nBut _not_ if the message is different:\n\n```bash\nnode --experimental-report --report-filename report-5.json \\\n  --report-uncaught-exception --eval \"throw new Error('pizza party')\"\n```\n\nAnd:\n\n```bash\nrtk transform -t stack-hash report-5.json\n```\n\nResults in:\n\n<EmbedCode name=\"transform-output-4\" language=\"json\" />\n\nYou can see that the `sha1` property is different, because the exception thrown has a different message.\n\n<InlineNotification>\n\nTransformers aren't limited to just the `transform` command; you can use transformers _combined with_ any other command (like `diff` or `inspect`) via the `--transform/-t` argument, as applicable. For example, converting the output of `inspect` to JSON for machine consumption. See the [CLI Guide]() for details.\n\n</InlineNotification>\n\n## Conclusion\n\nThat wraps up the <Metadata prop=\"packageName\"/> quick start guide! We've learned how to use <Metadata prop=\"packageName\"/> to:\n\n- Redact secrets from a diagnostic report\n- Diff two diagnostic reports\n- Check a diagnostic report for potential problems\n- Transform a diagnostic report to another format\n\nSee [below](#further-reading) for links to detailed documentation on all of the above topics.\n\n## Further Reading\n\n- [Programmatic API Documentation](/api/home)\n","type":"Mdx","contentDigest":"e8083bc1df382ac15d2a2d746726ed22","counter":98,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"report-toolkit Quick Start"},"exports":{},"rawBody":"---\ntitle: report-toolkit Quick Start\n---\n\nimport {Metadata, EmbedCode} from '../../components';\nimport {reportExample} from './index.module.scss';\n\n<PageDescription>\n\nThis \"quick start\" guide will provide an overview of <Metadata prop=\"packageName\"/>'s capabilities.\n\nUse the links below to jump to a section, or just <a href=\"#install\">install <Metadata prop=\"packageName\"/></a> and get moving!\n\n</PageDescription>\n\n<AnchorLinks>\n  <AnchorLink>Install</AnchorLink>\n  <AnchorLink>Generate a Diagnostic Report</AnchorLink>\n  <AnchorLink>Redact Secrets From a Report</AnchorLink>\n  <AnchorLink>Compare Two Reports</AnchorLink>\n  <AnchorLink>Detect Problems within a Report</AnchorLink>\n  <AnchorLink>Transforming a Report</AnchorLink>\n  <AnchorLink>Further Reading</AnchorLink>\n</AnchorLinks>\n\n## Install\n\nUnsurprisingly, to use <Metadata prop=\"packageName\"/>, you must install it.\n\n### Prerequisite: Node.js v11.8.0 or newer\n\nFor the purposes of this guide, _you must be running Node.js version v11.8.0 or newer_; the [Diagnostic Reports](https://nodejs.org/api/report.html) API referenced in this guide will reflect its state at version v11.8.0.\n\nHere are some options for installation:\n\n- **Recommended:** An official package from [nodejs.org](https://nodejs.org)\n- **macOS**: [Homebrew](https://brew.sh) (`brew install node`)\n- **Linux**: [NodeSource Binary Distributions](https://github.com/nodesource/distributions)\n- **Windows**: [Chocolatey](https://chocolatey.org/)\n- **Linux/macOS**: A version manager like [nvm](https://github.com/nvm-sh/nvm)\n\n### Package Installation\n\n<Row>\n<Column colMd={5} colLg={8}>\n\nUse your favorite Node.js package manager to install; [`npm`](https://docs.npmjs.com/cli-documentation/) comes packaged with most Node.js distributions.\n\nFor this guide, it's recommended to install <Metadata prop=\"packageName\"/> _globally_:\n\n```bash\n$ npm install report-toolkit --global\n```\n\n</Column>\n<Column colMd={2} colLg={3} offsetMd={1} offsetLg={1}>\n  <Aside>\n\nSee npm's guide on [installing packages globally](https://docs.npmjs.com/downloading-and-installing-packages-globally) for other options and troubleshooting.\n\n  </Aside>\n</Column>\n</Row>\n\n## Generate a Diagnostic Report\n\nTo do much of anything with <Metadata prop=\"packageName\"/>, you must generate a diagnostic report.\n\n<InlineNotification kind=\"info\">\n\nIf you already have a diagnostic report file you intend to use, you can skip\nahead to the [next section](#redact-secrets-from-a-report).\n\n</InlineNotification>\n\nAt the time of this writing (2019-09-23), the diagnostic report functionality is \"hidden\" behind a flag to the `node` executable; `--experimental-report`.\n\nThe quickest way to generate a report is to evaluate an inline script, like so:\n\n```bash\nnode --experimental-report --report-filename report.json --eval \"process.report.writeReport()\"\n```\n\nYou'll see this:\n\n```\nWriting Node.js report to file: report.json\nNode.js report completed\n(node:18881) ExperimentalWarning: report is an experimental feature. This feature could change at any time\n```\n\nBreaking down the arguments to `node`, we have:\n\n1. `--experimental-report`; enables diagnostic report functionality\n1. `--report-filename report.json`; whenever a diagnostic report is written to disk, use this filename\n1. `--eval \"process.report.writeReport()\"`; instead of a `.js` file, execute the double-quoted string as a script, then exit. The script calls [process.report.writeReport()](https://nodejs.org/api/process.html#process_process_report_writereport_filename_err), which writes a report file to disk.\n\n<p>\n  Next, you'll see how <Metadata prop=\"packageName\" /> enables safe storage and\n  transmission of report files.\n</p>\n\n## Redact Secrets From a Report\n\nOpen `report.json` in your favorite editor (or use `cat` or `less` or whathaveyou). Scroll down to--or search for--the `environmentVariables` property.\n\n`environmentVariables` is a top-level property of a report file. It contains a complete dump of the environment at the time the report was created. You might notice API keys, cloud provider tokens, credentials, or other session identifiers; in other words, _secrets_.\n\nDepending on your filesystem permissions, `report.json` might even be readable by other users who couldn't otherwise see your environment. This is a potential leak, and we should plug it. <Metadata prop=\"packageName\"/> to the rescue!\n\nThe <Metadata prop=\"packageName\"/> package provides command-line utility, <Metadata prop=\"executable\"/>.\n\nAssuming <Metadata prop=\"packageName\"/> is installed globally, run:\n\n```bash\nrtk --help\n```\n\nYou should see:\n\n<EmbedCode name=\"cli-output\" />\n\nWe see <Metadata prop=\"executable\"/> provides _commands_; the command we want is `redact`.\n\nBy default, the `redact` command will print its output to `STDOUT` (the terminal). Instead, let's use the `--output` option to write to a new file (smarties may also ask their shell to redirect the output to a file):\n\n```bash\nrtk redact --output report-redacted.json report.json\n```\n\n<Row>\n<Column colMd={5} colLg={8}>\n\nNow, open `report-redacted.json` in your editor (or otherwise display it). Search for the `environmentVariables` property. Within this object, you will see `[REDACTED]` wherever <Metadata prop=\"packageName\"/> found a secret.\n\nHere's an example _excerpt_ from `report-redacted.json`:\n\n</Column>\n<Column colMd={2} colLg={3} offsetMd={1} offsetLg={1}>\n  <Aside>\n\nIf <Metadata prop=\"packageName\"/> _didn't_ catch all your secrets, fear not; you can customize its behavior to suit your environment. See the [Configuration Guide](/configuration-guide) for more information.\n\n  </Aside>\n</Column>\n</Row>\n\n```json path=report-redacted.json\n{\n \"environmentVariables\": {\n    \"TERM_SESSION_ID\": \"[REDACTED]\",\n    \"SSH_AUTH_SOCK\": \"[REDACTED]\",\n    \"Apple_PubSub_Socket_Render\": \"[REDACTED]\",\n    \"COLORFGBG\": \"15;0\",\n    \"ITERM_PROFILE\": \"yoyodyne\"\n }\n```\n\nIf you wish, delete your original `report.json`; `report-redacted.json` is now safe to share or send across the wire.\n\nA design goal of <Metadata prop=\"packageName\"/> is _strong security defaults_. It will _always_ automatically redact _all_ reports which it ingests. You can disable this via a flag--see the detailed [CLI Guide](/cli-guide) for more information.\n\nNext, you'll see how <Metadata prop=\"executable\"/> can provide a quick comparison of two reports using its `diff` command.\n\n## Compare Two Reports\n\nIf you're having trouble tracking down the difference between two running `node` processes--say, on two machines that _should_ have identical environments--diagnostic reports and <Metadata prop=\"packageName\"/> can help.\n\nAs you may have deduced, we'll need two (2) reports to proceed.\n\n<InlineNotification>\n\nIf you've completed the [previous section](#redact-secrets-from-a-report), you can re-use `report-redacted.json`; use this filename whenever this section refers to `report-1.json`. Skip ahead to [creating the second report](#create-the-second-report).\n\n</InlineNotification>\n\n### Create the First Report\n\nTo create the first report, named `report-1.json`, execute:\n\n```bash\nnode --experimental-report --report-filename report-1.json \\\n  --eval \"process.report.writeReport()\"\n```\n\nYou'll see:\n\n```plain wrap=true\nWriting Node.js report to file: report-1.json\nNode.js report completed\n(node:18881) ExperimentalWarning: report is an experimental feature. This feature could change at any time\n```\n\n### Create the Second Report\n\nTo create a _second_ report, repeat the command with the filename changed to `report-2.json`:\n\n```bash\nnode --experimental-report --report-filename report-2.json \\\n  --eval \"process.report.writeReport()\"\n```\n\nAnd you will see:\n\n```plain wrap=true\nWriting Node.js report to file: report-2.json\nNode.js report completed\n(node:18881) ExperimentalWarning: report is an experimental feature. This feature could change at any time\n```\n\n<InlineNotification kind=\"warning\">\n  Remember, report files may contain secrets; be deliberate about what you do\n  with these files!\n</InlineNotification>\n\nWith our two reports in-hand, we can use the `diff` command to see what's changed between these two files.\n\n### Running a Diff\n\nA \"diff\" between two reports is _not_ a POSIX diff like you'd see between two versions of the same file. If you want that, you can use the [diff utility](https://en.wikipedia.org/wiki/Diff)!\n\nInstead, <Metadata prop=\"packageName\"/> attempts to disregard typically-irrelevant information, and provide output tailored to the data structure of a report file, which is JSON.\n\nTo display a diff, execute:\n\n```bash\nrtk diff report-1.json report-2.json\n```\n\nYou'll get something like the below (but probably with fancy colors):\n\n<EmbedCode name=\"diff-output\" />\n\nBy default, <Metadata prop=\"executable\"/> will display a diff in a tabular format, intended for human consumption.\n\nIn the table above, we have four (4) columns. Breaking them down:\n\n1. **Op**: This is the _type_ of change. In this case, all changes are _modifications_, denoted by `M`. This means that the field exists in both reports, but the value is different. You may also see `A` for \"added\" (when a field is present in the second report and not the first) and `D` for \"deleted\" (when a field is present in the first but not the second).\n1. **Path**: This is the JSON \"keypath\" of the field. If you were to reference the field like the report is a regular JavaScript object, this is how you would do it. `[]` indicates the presence of an _array_. `header.commandLine[3]`, for example, 4th element of the `commandLine` prop of the root `header` prop.\n1. **report-1.json**: The value at **Path** in `report-1.json` (if present).\n1. **report-2.json**: The corresponding value at **Path** in `report-2.json` (if present).\n\nNote the difference within the `header.commandLine` array. This reflects the different commands we used to generate each report. We could use that information to determine if the same application generated both reports. Likewise, by comparing `header.processId`, we could tell if the same _process_ created both reports.\n\n<Row>\n<Column colMd={5} colLg={8}>\n\nTo squelch noise, by default, the `diff` command shows differences _only_ within these properties:\n\n1. `header`, omitting properties:\n   1. `filename`\n   1. `dumpEventTime`\n   1. `dumpEventTimeStamp`\n   1. `cpus`\n1. `environmentVariables`\n1. `userLimits`\n1. `sharedObjects`\n\n</Column>\n<Column colMd={2} colLg={3} offsetMd={1} offsetLg={1}>\n  <Aside>\n\nYou can control which fields appear in the diff by providing the `--includeProp/-i` and/or `--excludeProp/-x` arguments, or use `--all` to show everything. See the [CLI Guide]() for more in-depth information.\n\n  </Aside>\n</Column>\n</Row>\n\nNext, we'll see how <Metadata prop=\"packageName\"/> can detect problems using its `inspect` command.\n\n## Detect Problems within a Report\n\nA diagnostic report is raw data about a `node` process. If you're familiar with diagnostic reports--or happen to know precisely what you're looking for--you can interpret that data yourself.\n\nBut much like a radiologist reading an X-ray, <Metadata prop=\"packageName\"/> can interpret the raw data in a report and provide akin to a _diagnosis_--or warn about something you may have otherwise overlooked.\n\nGiven a diagnostic report, <Metadata prop=\"packageName\"/> can run a set of _rules_ (heuristics) against it, providing further information if a \"check\" fails. This is similar--and, in fact, patterned on--how [ESLint](http://eslint.org) runs rules against your codebase. Also akin to ESLint, <Metadata prop=\"packageName\"/> ships with a set of built-in rules, which we'll use next.\n\nLet's take one of the reports we've already created (it doesn't matter which). Execute:\n\n```bash\nrtk inspect report-1.json\n```\n\nMost likely, this command will result in _no output_--in other words, success. <Metadata prop=\"executable\"/> didn't find anything worth your attention.\n\nEach _message_ emitted by a rule has an associated _severity_. These severities, from \"most severe\" to \"least severe\", are:\n\n- `error`\n- `warning`\n- `info`\n\nThe default behavior of <Metadata prop=\"executable\"/> is to exclusively show messages with a severity of _error_.\n\nBut you, the user, can control this. Let's change the severity threshold to `info`, and see what happens:\n\n```bash\nrtk inspect report-1.json --severity info\n```\n\nThe output should now look _something_ like this (and in color):\n\n<EmbedCode name=\"inspect-output-1\" />\n\nAbove, we see that two rules (`cpu-usage` and `memory-usage`) each output a message. Reading the message, we see that the allowed CPU usage and memory usage, respectively, are within the default thresholds for each rule.\n\nIf, for example, the CPU usage was greater than 50%, then instead of a message with severity `INFO`, the severity would be displayed as `ERROR`.\n\n<InlineNotification>\n\nWhen a message with severity `ERROR` is encountered during inspection, <Metadata prop=\"executable\"/>'s process with exit with a nonzero code (1).\n\n</InlineNotification>\n\nInstead of printing a fibonacci sequence in another process, we can use an example \"problem\" report file to see what an _actual_ error looks like. <a href=\"/raw/report-high-cpu-usage.example.json\" download>Download <inlineCode>report-high-cpu-usage.example.json</inlineCode></a>; we'll hand this file to `inspect`:\n\n```bash\nrtk inspect report-high-cpu-usage.example.json\n```\n\nNote that the above command _does not_ include `--severity info`. Now, we should see an error:\n\n<EmbedCode name=\"inspect-output-2\" />\n\nIn `report-high-cpu-usage.example.json`, the reported CPU usage (precisely, the _mean_ across all CPUs) is greater than the default threshold of 50%.\n\nYou could use this information to verify that the process isn't taking up too much CPU--or change the range (via a configuration file) to assert the process remains active--or even verify that utilization is high enough to justify paying for the compute!\n\n<InlineNotification>\n\nTo get the most out of the built-in rules--all of which are independently configurable--see the [Configuration Guide](). If you want to make your _own_ custom rules, see the [Plugin Developer's Guide]();\n\n</InlineNotification>\n\nFinally, let's see how <Metadata prop=\"executable\"/>'s `transform` command can help convert a report to a more useful format.\n\n## Transforming a Report\n\nThe `transform` command allows you to apply _one or more_ \"transformers\" to a diagnostic report.\n\nThe list of built-in transformers is as follows:\n\n- `csv`: Converts to CSV format\n- `filter`: Pick or omit certain properties\n- `json`: Converts to JSON format (the default)\n- `newline`: Converts to newline-delimited format, suitable for piping via shell, consumption via Node.js streams, etc.\n- `redact`: Redacts secrets\n- `stack-hash`: Computes a hash of the exception for metrics; helps answer \"have we seen this exception before?\"\n- `table`: The default transform for the `diff` and `inspect` commands, among others\n\nSince this _is_ supposed to be a quick-start guide, we'll pick two of these as examples: [`filter`](#the-filter-transformer) and [`stack-hash`](#the-stack-hash-transformer).\n\n### The `filter` Transformer\n\nThe `filter` transformer allows you to essentially \"whitelist\" or \"blacklist\" some portion of a report (or both at once; the blacklist takes preference).\n\nFor example, if you'd like to retrieve _only_ the version of `node` used to generate the report, you can use:\n\n```bash\nrtk transform -t filter --include header.componentVersions.node \\\n  report-1.json\n```\n\nWhich will result in something like this (depending on the version of `node` you used to generate the report):\n\n<EmbedCode name=\"transform-output-1\" language=\"json\" />\n\nLikewise, the `--exclude` argument would allow you to, say, omit the entirety the `environmentVariables` and `sharedObjects` properties:\n\n```bash\nrtk transform -t filter --exclude environmentVariables --exclude \\\n  sharedObjects report-1.json\n```\n\nAs you can see from the above, `--include` and `--exclude` can be specified multiple times.\n\nFor something more practical, let's try `stack-hash`.\n\n### The `stack-hash` Transformer\n\nThe intent of this transformer is to facilitate the gathering of _metrics_ around exceptions (or more specifically, the stack traces thereof).\n\n`node` can be configured to automatically generate a diagnostic report when it encounters an uncaught exception or a user signal (e.g., `SIGUSR1`). We can then use the `stack-hash` transformer to associate the stack (present in all reports) with a reasonably unique SHA1 hash.\n\nHere's an example of configuring `node` to automatically output a report file upon an uncaught exception (and summarily throwing one via `--eval`):\n\n```bash\nnode --experimental-report --report-filename report-3.json \\\n  --report-uncaught-exception --eval \"throw new Error('oh no')\"\n```\n\nWe can then use the `stack-hash` transformer on `report-3.json`:\n\n```bash\nrtk transform -t stack-hash report-3.json\n```\n\nWhich will result in something akin to:\n\n<EmbedCode name=\"transform-output-2\" language=\"json\" />\n\nIf we repeat the command using a different filename (`report-4.json`):\n\n```bash\nnode --experimental-report --report-filename report-4.json \\\n  --report-uncaught-exception --eval \"throw new Error('oh no')\"\n```\n\nAnd run the transformer:\n\n```bash\nrtk transform -t stack-hash report-4.json\n```\n\nWe'll get the _same_ hash, even though the `dumpEventTime` (when the report file was created) and `filepath` differ:\n\n<EmbedCode name=\"transform-output-3\" language=\"json\" />\n\nBut _not_ if the message is different:\n\n```bash\nnode --experimental-report --report-filename report-5.json \\\n  --report-uncaught-exception --eval \"throw new Error('pizza party')\"\n```\n\nAnd:\n\n```bash\nrtk transform -t stack-hash report-5.json\n```\n\nResults in:\n\n<EmbedCode name=\"transform-output-4\" language=\"json\" />\n\nYou can see that the `sha1` property is different, because the exception thrown has a different message.\n\n<InlineNotification>\n\nTransformers aren't limited to just the `transform` command; you can use transformers _combined with_ any other command (like `diff` or `inspect`) via the `--transform/-t` argument, as applicable. For example, converting the output of `inspect` to JSON for machine consumption. See the [CLI Guide]() for details.\n\n</InlineNotification>\n\n## Conclusion\n\nThat wraps up the <Metadata prop=\"packageName\"/> quick start guide! We've learned how to use <Metadata prop=\"packageName\"/> to:\n\n- Redact secrets from a diagnostic report\n- Diff two diagnostic reports\n- Check a diagnostic report for potential problems\n- Transform a diagnostic report to another format\n\nSee [below](#further-reading) for links to detailed documentation on all of the above topics.\n\n## Further Reading\n\n- [Programmatic API Documentation](/api/home)\n","fileAbsolutePath":"/Users/boneskull/projects/boneskull/report-toolkit/packages/docs/src/pages/quick-start/index.mdx"}}}}